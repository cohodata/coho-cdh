#!/usr/bin/env python

#------------------------------------------------------------------------------
# Copyright (c) 2017 Coho Data Inc.
#
# The subject matter distributed under this license is or is based on
# information and material generated by Coho Data Inc. It may only be
# acquired, used, modified and distributed under the terms of the Coho
# Data Compute Cluster License v1.0.  Except as permitted in the Coho
# Data Compute Cluster License v1.0, all other rights are reserved in
# any copyright or other similar rights which may exist. Execution of
# software distributed under this Coho Data Compute Cluster License
# v1.0 may cause you to acquire third-party software (as described in
# the accompanying documentation) and you agree (a) to comply with the
# applicable licenses thereunder and (b) that Coho is not responsible
# in any way for your compliance or non-compliance with the applicable
# third-party licenses or the consequences of your being subject to
# said licenses or your compliance or non-compliance.
#------------------------------------------------------------------------------

"""Script to deploy a CDH compute cluster on a Coho Data DataStream
system.

Usage:
    $ docker run --rm -ti cohodata/yarn:2.9 /usr/bin/deploy-cdh-cluster.py --docker-portal=<portal_addr> --yarn-image=<registry_ip>:5000/cohodata/yarn:2.9 create <number_of_nodemanagers>
"""
from __future__ import print_function

import sys
import datetime
import tempfile
from collections import OrderedDict
import subprocess

RESOURCEMANAGER = 'resourcemanager'
NODEMANAGER = 'nodemanager'
HISTORYSERVER = 'historyserver'
YARN_IMAGE = 'cohodata/yarn:2.9'
DEFAULT_NMVOLTYPE = 'temporary'
DEFAULT_NMVOLSIZE = 3000

DOCKER_COMPOSE = '/usr/local/bin/docker-compose'

CONFIG = {}

#------------------------------------------------------------------------------
# We store everything in a global CONFIG dictionary so that when multiple steps
# are run in the same script invocation, we don't keep fetching the same bits
# of information over and over from the API.
def get_cfg(key):
    """Retrieve configuration values"""

    value = CONFIG.get(key, None)
    if value is not None:
        return value

    # Fill in the value as necessary
    if key == 'yarn_image':
        CONFIG[key] = YARN_IMAGE

    elif key == 'docker_portal':
        print('A docker portal address must be specified.')
        sys.exit(1)

    else:
        return None

    return CONFIG[key]


#------------------------------------------------------------------------------
#------------------------------------------------------------------------------
# Functions for defining the docker compose recipe

#------------------------------------------------------------------------------
def compose_nmvolname(node):
    """Return the name of a nodemanager volume"""

    return 'nodemanager{:08d}-vol'.format(node)

#------------------------------------------------------------------------------
def compose_list(label, values, indent_level):
    """Returns a list given an array of values and an indent level"""

    indent = 4
    prefix = ' ' * indent_level * indent
    ret = ''
    if label is not None:
        ret += prefix + label + ':\n'
        prefix += ' ' * indent
    for val in values:
        ret += prefix + val + '\n'
    return ret

#------------------------------------------------------------------------------
#pylint: disable=too-many-arguments
def compose_service(name, cmd, role=None, volumes=None, depends=None,
                    options=None):
    """Returns a docker compose recipe stanza describing a service"""

    env = ''
    if role is not None:
        env = compose_list('environment', ['ROLE: \'%s\'' % role], 2)

    vol = ''
    if volumes is not None:
        vol = compose_list('volumes', ['- %s' % v for v in volumes], 2)

    dep = ''
    if depends is not None:
        dep = compose_list('depends_on', ['- %s' % d for d in depends], 2)

    extra = ''
    if options is not None:
        extra = compose_list(None, options, 2)

    image = get_cfg('yarn_image')
    stanza = r"""    %s:
        container_name: %s
        image: %s
        command: %s
%s%s%s%s""" % (name, name, image, cmd, env, vol, dep, extra)
    stanza += '\n'
    return stanza
#pylint: enable=too-many-arguments

#------------------------------------------------------------------------------
INSTALL_INFO = '/opt/cio/etc/install_info:/install_info:ro'
HADOOP_RUN = '/usr/local/bin/cio-hadoop-run'

def compose_hadoop_service(name):
    """Returns a docker compose recipe stanza describing a hadoop service"""

    return compose_service(name,
                           [HADOOP_RUN, '--name=%s' % name],
                           role=('%s' % name),
                           volumes=[INSTALL_INFO])

def compose_hadoop_nm(nodes=()):
    """Returns a docker compose recipe stanza describing a nodemanager"""

    stanza = ''
    for node in nodes:
        name = 'nodemanager{:08d}'.format(node)
        tmpvol = compose_nmvolname(node)
        stanza += compose_service(name,
                                  '\'%s\'' % HADOOP_RUN,
                                  role='nodemanager',
                                  volumes=[INSTALL_INFO, '%s:/mnt' % tmpvol],
                                  depends=['resourcemanager', 'historyserver'])
    return stanza

def compose_hadoop_client():
    """Returns a docker compose recipe stanza describing a hadoop client"""

    return compose_service('client',
                           '\'/bin/bash\'',
                           depends=['resourcemanager'],
                           options=['user: hdfs', 'stdin_open: true',
                                    'tty: true'])

#------------------------------------------------------------------------------
def compose_services(nodes=()):
    """Returns a docker compose recipe stanza describing services"""

    stanza = 'services:\n'
    stanza += compose_hadoop_service('resourcemanager')
    stanza += compose_hadoop_service('historyserver')
    stanza += compose_hadoop_nm(nodes)
    stanza += compose_hadoop_client()
    return stanza

#------------------------------------------------------------------------------
def compose_volume(name, voltype, size):
    """Returns a docker compose recipe stanza describing a volume"""

    stanza = r"""    %s:
        driver: cohovolume
        driver_opts:
            type:   %s
            SizeMB: %s""" % (name, voltype, size)
    return stanza

#------------------------------------------------------------------------------
def compose_volumes(nodes=()):
    """Returns a docker compose recipe stanza describing volumes"""

    stanza = 'volumes:\n'
    for node in nodes:
        name = compose_nmvolname(node)
        voltype = DEFAULT_NMVOLTYPE
        size = DEFAULT_NMVOLSIZE
        stanza += compose_volume(name, voltype, size)
        stanza += '\n'
    return stanza

#------------------------------------------------------------------------------
def compose_network(network):
    """Returns a docker compose recipe stanza describing a network"""

    stanza = r"""    default:
        external:
            name: %s""" % (network)
    return stanza

#------------------------------------------------------------------------------
def compose_networks(networks):
    """Returns a docker compose recipe stanza describing networks"""

    stanza = 'networks:\n'
    for network in networks:
        stanza += compose_network(network)
        stanza += '\n'
    return stanza

#------------------------------------------------------------------------------
#------------------------------------------------------------------------------
def mk_check():
    """Verify that the user is not deploying more nodes than MAs in the
       cluster.  Once we have docker-py, we can use docker info"""
    pass

def compose_recipe(nodes):
    """Returns a docker compose recipe for the CDH cluster"""

    if nodes is None or not nodes:
        nodes = [0]
    networks = ['network0']
    stanzas = 'version: \'2\'\n\n'
    stanzas += compose_services(nodes)
    stanzas += '\n'
    stanzas += compose_volumes(nodes)
    stanzas += '\n'
    stanzas += compose_networks(networks)
    stanzas += '\n'
    if get_cfg('debug'):
        print(stanzas)
    return stanzas

def compose_command(cmd, recipe):
    """Executes docker-compose command against a recipe"""

    portal = get_cfg('docker_portal')
    debug = get_cfg('debug')
    with tempfile.NamedTemporaryFile(delete=not debug) as recipefile:
        recipefile.write(recipe)
        recipefile.flush()
        yaml = recipefile.name
        rawcmd = '%s -H %s -f %s %s' % (DOCKER_COMPOSE, portal, yaml, cmd)
        if debug:
            print('docker-compose recipe file: %s' % yaml)
            print('Command: %s' % rawcmd)
        splitcmd = rawcmd.split()
        try:
            ret = subprocess.check_output(splitcmd)
            print(ret)
        except subprocess.CalledProcessError as exc:
            error = 'Running docker-compose %s error: %s' % (cmd, str(exc))
            print(error)
            sys.exit(1)


def compose_up():
    """Executes docker-compose up -d"""

    nodes = xrange(get_cfg('instances'))
    recipe = compose_recipe(nodes)
    return compose_command('up -d', recipe)

def compose_down():
    """Executes docker-compose down"""

    # We can't expect that the docker-compose recipe file used to create the
    # cluster is still available when it comes time to delete the cluster.
    # Yet, we don't want the user to have to specify the number of nodemanager
    # instances to bring down a cluster.
    #
    # We could solve this by listing all the nodemanagers and explicitly put
    # those in a new recipe.
    # eg. docker -H <portal> ps --filter name=nodemanager
    #
    # Instead, we will rely on docker-compose to figure it out.  We specify
    # only a bogus nodemanager in the recipe; the nodemanagers will become
    # orphans when the cluster is taken down, and we ask docker-compose to
    # remove the orphans.
    nodes = [99999999]
    recipe = compose_recipe(nodes)
    return compose_command('down --remove-orphans', recipe)

#------------------------------------------------------------------------------
MK_ACTIONS = OrderedDict([('mk-check', mk_check),
                          ('up', compose_up),
                         ])

RM_ACTIONS = OrderedDict([('down', compose_down),
                         ])

def argparser():
    """Parse arugments"""

    from argparse import ArgumentParser, SUPPRESS
    parse = ArgumentParser(description='COHO CDH Hadoop compute cluster '
                           'management script.')
    parse.add_argument('-p', '--docker-portal', type=str,
                       help='The docker portal, with port suffix')
    parse.add_argument('-i', '--yarn-image', type=str,
                       help='Yarn image, with the registry and tag')
    parse.add_argument('-d', '--debug', action='store_true', help=SUPPRESS)
    subp = parse.add_subparsers(metavar='command',
                                dest='command',
                                help='One of: create, delete')

    pcreate = subp.add_parser('create', help='Create compute cluster')
    pcreate.set_defaults(command='create')
    pcreate.add_argument('instances', type=int,
                         help='Number of Node Manager instances to deploy')

    pdelete = subp.add_parser('delete', help='Destroy compute cluster')
    pdelete.set_defaults(command='delete')
    return parse

def usage(parser):
    """Print help"""

    parser.print_help()
    sys.exit(1)

if __name__ == '__main__':
    _P = argparser()
    _ARGS = vars(_P.parse_args())

    CONFIG['debug'] = _ARGS.get('debug', False)
    CONFIG['yarn_image'] = _ARGS.get('yarn_image', YARN_IMAGE)
    CONFIG['docker_portal'] = _ARGS.get('docker_portal', None)
    COMMAND = _ARGS.get('command', '')


    STEPS = []
    if COMMAND == 'create':
        CONFIG['instances'] = _ARGS.get('instances', 1)
        if CONFIG['instances'] < 1:
            print('Error: Invalid number of Node Manager instances (%s).' %
                  CONFIG['instances'])
            sys.exit(1)
        STEPS = list(MK_ACTIONS)

    elif COMMAND == 'delete':
        STEPS = list(RM_ACTIONS)

    if CONFIG['debug'] is True:
        print(STEPS)
    ACTIONS = dict(MK_ACTIONS)
    ACTIONS.update(RM_ACTIONS)

    for step in STEPS:
        if step is '':
            continue
        if CONFIG['debug'] is True:
            print('----------------------------------------------------------')
            print('>>> %s: Starting %s' %
                  (datetime.datetime.now().isoformat(), step))
        if not ACTIONS.has_key(step):
            print('Invalid step: %s!' % step)
            sys.exit(1)
        ACTIONS[step]()
        if CONFIG['debug'] is True:
            print('>>> %s: Completed %s' %
                  (datetime.datetime.now().isoformat(), step))

    if COMMAND == 'create':
        print('Success: compute cluster created.')

    elif COMMAND == 'delete':
        print('Success: compute cluster deleted.')

