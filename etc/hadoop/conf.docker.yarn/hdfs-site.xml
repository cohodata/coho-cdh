<?xml version="1.0"?>
<!--
  Copyright (c) 2016 Coho Data Inc.
  The subject matter distributed under this license is or is based on
  information and material generated by Coho Data Inc. It may only be
  acquired, used, modified and distributed under the terms of the Coho
  Data Compute Cluster License v1.0.  Except as permitted in the Coho
  Data Compute Cluster License v1.0, all other rights are reserved in
  any copyright or other similar rights which may exist. Execution of
  software distributed under this Coho Data Compute Cluster License
  v1.0 may cause you to acquire third-party software (as described in
  the accompanying documentation) and you agree (a) to comply with the
  applicable licenses thereunder and (b) that Coho is not responsible
  in any way for your compliance or non-compliance with the applicable
  third-party licenses or the consequences of your being subject to
  said licenses or your compliance or non-compliance.
-->
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>

  <!-- 1-way replication -->
  <property>
    <name>dfs.replication</name>
    <value>1</value>
  </property>

  <!-- disable file chunking by setting a large blocksize value (1 exabyte) -->
  <!-- <property> -->
  <!--   <name>dfs.blocksize</name> -->
  <!--   <value>1e</value> -->
  <!-- </property> -->

  <!-- disable permissions -->
  <property>
     <name>dfs.permissions</name>
     <value>false</value>
  </property>

  <!-- MapReduce intermediate file storage -->
  <property>
     <name>hadoop.tmp.dir</name>
     <value>/var/lib/hadoop-hdfs/cache/${user.name}</value>
  </property>

  <!-- NameNode metadata storage locations -->
  <property>
     <name>dfs.namenode.name.dir</name>
     <value>file:///var/lib/hadoop-hdfs/cache/hadoop/dfs/name</value>
  </property>
  <property>
     <name>dfs.namenode.checkpoint.dir</name>
     <value>file:///var/lib/hadoop-hdfs/cache/hadoop/dfs/namesecondary</value>
  </property>

  <!-- DataNode storage location -->
  <property>
     <name>dfs.datanode.data.dir</name>
     <value>file:///var/lib/hadoop-hdfs/cache/hadoop/dfs/data</value>
  </property>

  <!-- Immediately exit safemode as soon as one DataNode checks in. 
       On a multi-node cluster, these configurations must be removed.  -->
  <property>
    <name>dfs.safemode.extension</name>
    <value>0</value>
  </property>
  <property>
     <name>dfs.safemode.min.datanodes</name>
     <value>1</value>
  </property>

  <!-- HDFS timeout values -->
  <property>
    <name>dfs.datanode.socket.write.timeout</name>
    <value>0</value>
  </property>
  <property>
    <name>dfs.datanode.socket.read.timeout</name>
    <value>0</value>
  </property>
  <property>
    <name>dfs.socket.timeout</name>
    <value>0</value>
  </property>
  <property>
    <name>dfs.client.socket-timeout</name>
    <value>0</value>
  </property>

  <property>
    <name>dfs.client-write-packet-size</name>
    <value>524288</value>
  </property>

</configuration>
